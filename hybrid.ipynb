{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with MEAN PHOTON metric...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Academic\\Dual Degree Project\\DDP\\boson_env\\lib\\site-packages\\scipy\\sparse\\_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csc_array is expensive. lil and dok are more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 124 | Loss: 1.0671\n",
      "Epoch 1 | Avg Loss: 1.0822 | Time: 839.5s\n",
      "Test AUC: 0.3764\n",
      "Batch 1 | Loss: 0.9781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Academic\\Dual Degree Project\\DDP\\boson_env\\lib\\site-packages\\scipy\\sparse\\_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csc_array is expensive. lil and dok are more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4 | Loss: 1.0767"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 332\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# Inside your training loop...\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m batch_idx:\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;66;03m# pred range is [-1.0, +1.0]\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m     y_target \u001b[38;5;241m=\u001b[39m y_train[idx]\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;66;03m# --- Robust MSE (Fidelity Loss) ---\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 209\u001b[0m, in \u001b[0;36mHybridFraudDetector.forward\u001b[1;34m(self, x_raw)\u001b[0m\n\u001b[0;32m    206\u001b[0m encoding_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_layer2(h1_act) \n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Quantum Pass\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mQuantumOp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantum_circuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[1;32mIn[1], line 93\u001b[0m, in \u001b[0;36mQuantumOp.__init__\u001b[1;34m(self, circuit_builder, weights, inputs)\u001b[0m\n\u001b[0;32m     91\u001b[0m w_vals \u001b[38;5;241m=\u001b[39m [w\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights]\n\u001b[0;32m     92\u001b[0m i_vals \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs]\n\u001b[1;32m---> 93\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_vals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(val, parents, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantumHybrid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 103\u001b[0m, in \u001b[0;36mQuantumOp._run_simulation\u001b[1;34m(self, w_vals, i_vals)\u001b[0m\n\u001b[0;32m    100\u001b[0m circ \u001b[38;5;241m=\u001b[39m bosonic_qiskit\u001b[38;5;241m.\u001b[39mCVCircuit(qmr, cr)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# 2. Build User Circuit\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcircuit_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcirc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# 3. CRITICAL CHANGE: Do NOT add cv_measure here.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# We want the state vector, not the measurement counts.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[1], line 240\u001b[0m, in \u001b[0;36mHybridFraudDetector.quantum_circuit\u001b[1;34m(circuit, weights, inputs, qmr)\u001b[0m\n\u001b[0;32m    236\u001b[0m circuit\u001b[38;5;241m.\u001b[39mcv_sq(sq_1, qmr[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# Beam Splitter: BSgate(layer[:,4], layer[:,5])\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# Bosonic Qiskit BS takes (theta, phi, q1, q2)\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_bs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqmr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqmr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# Rotation: Rgate(layer[:,6])\u001b[39;00m\n\u001b[0;32m    243\u001b[0m circuit\u001b[38;5;241m.\u001b[39mcv_r(inputs[\u001b[38;5;241m6\u001b[39m], qmr[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32md:\\Academic\\Dual Degree Project\\DDP\\boson_env\\lib\\site-packages\\bosonic_qiskit\\circuit.py:477\u001b[0m, in \u001b[0;36mCVCircuit.cv_bs\u001b[1;34m(self, theta, qumode_a, qumode_b, duration, unit)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcv_bs\u001b[39m(\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    456\u001b[0m     theta: \u001b[38;5;28mcomplex\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    460\u001b[0m     unit: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mns\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    461\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m InstructionSet:\n\u001b[0;32m    462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Two-mode beam splitter gate.\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03m        Instruction: QisKit instruction\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_gate(\n\u001b[0;32m    474\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mbs,\n\u001b[0;32m    475\u001b[0m             [theta],\n\u001b[0;32m    476\u001b[0m             cutoffs\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m--> 477\u001b[0m                 \u001b[43mQumodeRegister\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_cutoff\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mqumode_a\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    478\u001b[0m                 QumodeRegister\u001b[38;5;241m.\u001b[39mcalculate_cutoff(\u001b[38;5;28mlen\u001b[39m(qumode_b)),\n\u001b[0;32m    479\u001b[0m             ],\n\u001b[0;32m    480\u001b[0m             num_qubits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(qumode_a) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(qumode_b),\n\u001b[0;32m    481\u001b[0m             label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBS\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    482\u001b[0m             duration\u001b[38;5;241m=\u001b[39mduration,\n\u001b[0;32m    483\u001b[0m             unit\u001b[38;5;241m=\u001b[39munit,\n\u001b[0;32m    484\u001b[0m         ),\n\u001b[0;32m    485\u001b[0m         qargs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m*\u001b[39mqumode_a, \u001b[38;5;241m*\u001b[39mqumode_b],\n\u001b[0;32m    486\u001b[0m     )\n",
      "File \u001b[1;32md:\\Academic\\Dual Degree Project\\DDP\\boson_env\\lib\\site-packages\\bosonic_qiskit\\qumoderegister.py:47\u001b[0m, in \u001b[0;36mQumodeRegister.calculate_cutoff\u001b[1;34m(num_qubits_per_qumode)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcutoff\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_cutoff(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_qubits_per_qumode)\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcalculate_cutoff\u001b[39m(num_qubits_per_qumode: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnum_qubits_per_qumode\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_qumode_index\u001b[39m(\u001b[38;5;28mself\u001b[39m, qubit: Qubit) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import bosonic_qiskit\n",
    "import qiskit\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import cmath\n",
    "\n",
    "# --- 1. Autograd Engine (Value Class) ---\n",
    "class Value:\n",
    "    def __init__(self, data, _children=(), _op=''):\n",
    "        self.data = data\n",
    "        self.grad = 0\n",
    "        self._backward = lambda: None\n",
    "        self._prev = set(_children)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data + other.data, (self, other), '+')\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * out.grad\n",
    "            other.grad += 1.0 * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __neg__(self):\n",
    "        return self * Value(-1)\n",
    "\n",
    "    def log(self):\n",
    "        val = self.data\n",
    "        # Clip to prevent log(0) = -inf\n",
    "        if val < 1e-7: val = 1e-7\n",
    "        if val > 1.0 - 1e-7: val = 1.0 - 1e-7\n",
    "        \n",
    "        out = Value(np.log(val), (self,), 'log')\n",
    "        def _backward():\n",
    "            self.grad += (1.0 / val) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, (self, other), '*')\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "        \n",
    "    def tanh(self):\n",
    "        # Tanh activation allows negative values (Phase Space!)\n",
    "        x = self.data\n",
    "        t = (np.exp(2*x) - 1)/(np.exp(2*x) + 1)\n",
    "        out = Value(t, (self,), 'tanh')\n",
    "        def _backward():\n",
    "            self.grad += (1 - t**2) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "        self.grad = 1\n",
    "        for v in reversed(topo):\n",
    "            v._backward()\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        self.grad = 0\n",
    "\n",
    "# --- 2. Improved Quantum Op (Using a Custom Observable) ---\n",
    "class QuantumOp(Value):\n",
    "    def __init__(self, circuit_builder, weights, inputs, cutoff_dim=2):\n",
    "        self.weights = weights\n",
    "        self.inputs = inputs\n",
    "        self.circuit_builder = circuit_builder\n",
    "        self.cutoff_dim = cutoff_dim\n",
    "        \n",
    "        # --- Define the observable for our HYBRID classification task ---\n",
    "        cv_dim = self.cutoff_dim ** 2\n",
    "        \n",
    "        o_cv = np.zeros((cv_dim, cv_dim))\n",
    "        fraud_idx = 1\n",
    "        normal_idx = self.cutoff_dim\n",
    "        o_cv[fraud_idx, fraud_idx] = 1.0\n",
    "        o_cv[normal_idx, normal_idx] = -1.0\n",
    "        \n",
    "        i_qubit = np.identity(2)\n",
    "        self.observable = np.kron(i_qubit, o_cv)\n",
    "        \n",
    "        parents = tuple(weights + inputs)\n",
    "        \n",
    "        w_vals = [w.data for w in self.weights]\n",
    "        i_vals = [i.data for i in self.inputs]\n",
    "        val = self._run_simulation(w_vals, i_vals)\n",
    "        super().__init__(val, parents, 'QuantumHybrid')\n",
    "\n",
    "    def _run_simulation(self, w_vals, i_vals):\n",
    "        # 1. Setup a HYBRID Circuit\n",
    "        qmr = bosonic_qiskit.QumodeRegister(num_qumodes=2, num_qubits_per_qumode=self.cutoff_dim)\n",
    "        qr = qiskit.QuantumRegister(1)\n",
    "        cr = qiskit.ClassicalRegister(3)\n",
    "        \n",
    "        circ = bosonic_qiskit.CVCircuit(qmr, qr, cr)\n",
    "        \n",
    "        # 2. Build User Circuit, passing both registers\n",
    "        self.circuit_builder(circ, w_vals, i_vals, qmr, qr)\n",
    "        \n",
    "        try:\n",
    "            state, _, _ = bosonic_qiskit.util.simulate(circ)\n",
    "            probs = state.probabilities()\n",
    "            p_fraud = probs[1]\n",
    "            return p_fraud\n",
    "        except Exception as e:\n",
    "            print(f\"Simulation failed: {e}\")\n",
    "            return 0.5\n",
    "\n",
    "    def _backward(self):\n",
    "        h = 0.001 \n",
    "        w_numerics = [w.data for w in self.weights]\n",
    "        i_numerics = [i.data for i in self.inputs]\n",
    "        for idx, w in enumerate(self.weights):\n",
    "            w_copy = w_numerics.copy()\n",
    "            w_copy[idx] += h\n",
    "            out_plus = self._run_simulation(w_copy, i_numerics)\n",
    "            w_copy[idx] -= 2*h\n",
    "            out_minus = self._run_simulation(w_copy, i_numerics)\n",
    "            grad = (out_plus - out_minus) / (2*h)\n",
    "            w.grad += self.grad * grad\n",
    "        for idx, inp in enumerate(self.inputs):\n",
    "            i_copy = i_numerics.copy()\n",
    "            i_copy[idx] += h\n",
    "            out_plus = self._run_simulation(w_numerics, i_copy)\n",
    "            i_copy[idx] -= 2*h\n",
    "            out_minus = self._run_simulation(w_numerics, i_copy)\n",
    "            grad = (out_plus - out_minus) / (2*h)\n",
    "            inp.grad += self.grad * grad\n",
    "\n",
    "# --- 3. Hybrid Model with Tanh & Strong Init ---\n",
    "class LinearLayer:\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.weights = [[Value(random.gauss(0, 0.2)) for _ in range(n_out)] for _ in range(n_in)]\n",
    "        self.bias = [Value(0.1) for _ in range(n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        out = []\n",
    "        for j in range(len(self.bias)):\n",
    "            act = self.bias[j]\n",
    "            for i in range(len(x)):\n",
    "                act = act + x[i] * self.weights[i][j]\n",
    "            out.append(act)\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for row in self.weights for p in row] + self.bias\n",
    "\n",
    "class HybridFraudDetector:\n",
    "    def __init__(self, n_features):\n",
    "        self.c_layer1 = LinearLayer(n_features, 20)\n",
    "        self.c_layer2 = LinearLayer(20, 14) \n",
    "        \n",
    "        self.q_weights = []\n",
    "        for i in range(21):\n",
    "            val = random.uniform(-0.1, 0.1) \n",
    "            self.q_weights.append(Value(val))\n",
    "            \n",
    "    def forward(self, x_raw):\n",
    "        x_vals = [Value(xi) for xi in x_raw]\n",
    "        h1 = self.c_layer1(x_vals)\n",
    "        h1_act = [h.tanh() for h in h1]\n",
    "        encoding_params = self.c_layer2(h1_act) \n",
    "        out = QuantumOp(self.quantum_circuit, self.q_weights, encoding_params)\n",
    "        return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def quantum_circuit(circuit, weights, inputs, qmr, qr):\n",
    "        def to_complex(mag, phase):\n",
    "            return mag * cmath.exp(1j * phase)\n",
    "\n",
    "        sq_0 = to_complex(inputs[0], inputs[1])\n",
    "        sq_1 = to_complex(inputs[2], inputs[3])\n",
    "        circuit.cv_sq(sq_0, qmr[0])\n",
    "        circuit.cv_sq(sq_1, qmr[1])\n",
    "        circuit.cv_bs(inputs[4], qmr[0], qmr[1])\n",
    "        circuit.cv_r(inputs[6], qmr[0])\n",
    "        circuit.cv_r(inputs[7], qmr[1])\n",
    "        d_0 = to_complex(inputs[8], inputs[9])\n",
    "        d_1 = to_complex(inputs[10], inputs[11])\n",
    "        circuit.cv_d(d_0, qmr[0])\n",
    "        circuit.cv_d(d_1, qmr[1])\n",
    "        \n",
    "        circuit.cv_bs(weights[0], qmr[0], qmr[1])\n",
    "        circuit.cv_r(weights[2], qmr[0])\n",
    "        circuit.cv_r(weights[3], qmr[1])\n",
    "        s_var_0 = to_complex(weights[4], weights[5])\n",
    "        s_var_1 = to_complex(weights[6], weights[7])\n",
    "        circuit.cv_sq(s_var_0, qmr[0])\n",
    "        circuit.cv_sq(s_var_1, qmr[1])\n",
    "        circuit.cv_bs(weights[8], qmr[0], qmr[1])\n",
    "        circuit.cv_r(weights[10], qmr[0])\n",
    "        circuit.cv_r(weights[11], qmr[1])\n",
    "        d_var_0 = to_complex(weights[12], weights[13])\n",
    "        d_var_1 = to_complex(weights[14], weights[15])\n",
    "        circuit.cv_d(d_var_0, qmr[0])\n",
    "        circuit.cv_d(d_var_1, qmr[1])\n",
    "        \n",
    "        circuit.h(qr[0])\n",
    "        circuit.ry(weights[18], qr[0])\n",
    "        \n",
    "        cd_alpha = to_complex(weights[19], weights[20])\n",
    "        circuit.cv_c_d(cd_alpha, [qmr[0]], qr[0])\n",
    "        \n",
    "    def parameters(self):\n",
    "        return self.c_layer1.parameters() + self.c_layer2.parameters() + self.q_weights\n",
    "    \n",
    "# --- 4. Training - MODIFIED FOR STABILITY ---\n",
    "def get_full_data(n_samples=1000):\n",
    "    try:\n",
    "        df = pd.read_csv(r\"D:\\Academic\\QML_Intern\\Anomaly_Detection\\Fraud_Detection\\creditcard_data.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERROR: Please update the path to 'creditcard_data.csv'\")\n",
    "        return None, None, None, None\n",
    "        \n",
    "    fraud = df[df['Class'] == 1]\n",
    "    normal = df[df['Class'] == 0]\n",
    "    n_per = n_samples // 2\n",
    "    fraud = resample(fraud, n_samples=n_per, random_state=42)\n",
    "    normal = resample(normal, n_samples=n_per, random_state=42)\n",
    "    df_bal = pd.concat([fraud, normal])\n",
    "    \n",
    "    X = df_bal.drop(['Class', 'Time'], axis=1).values\n",
    "    y = df_bal['Class'].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Setup\n",
    "X_train, X_test, y_train, y_test = get_full_data(n_samples=10000)\n",
    "if X_train is not None:\n",
    "    model = HybridFraudDetector(n_features=29)\n",
    "    optimizer_params = model.parameters()\n",
    "    epochs = 10\n",
    "    \n",
    "    # --- CHANGE 1: Lower the learning rate ---\n",
    "    # Cross-entropy can produce large gradients, so a smaller LR is needed for stability.\n",
    "    lr = 0.001 \n",
    "    \n",
    "    print(f\"Training with BINARY CROSS-ENTROPY loss...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        start = time.time()\n",
    "        indices = np.random.permutation(len(X_train))\n",
    "        \n",
    "        for i in range(0, len(X_train), 64):\n",
    "            batch_idx = indices[i:i+64]\n",
    "            batch_loss = Value(0)\n",
    "            \n",
    "            for idx in batch_idx:\n",
    "                # pred is now a probability p in [0, 1]\n",
    "                p = model.forward(X_train[idx])\n",
    "                y_target = y_train[idx]\n",
    "                \n",
    "                # --- CHANGE FOR CROSS-ENTROPY ---\n",
    "                # Loss = -(y*log(p) + (1-y)*log(1-p))\n",
    "                y = Value(y_target)\n",
    "                term = (y * p.log() + (Value(1) + y.__neg__()) * (Value(1) + p.__neg__()).log()).__neg__()\n",
    "                \n",
    "                batch_loss = batch_loss + term\n",
    "                \n",
    "            batch_loss = batch_loss * Value(1.0/64)\n",
    "            \n",
    "            # Zero Grads & Backprop\n",
    "            for p in optimizer_params: p.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            \n",
    "            # --- CHANGE 2: Implement Gradient Clipping ---\n",
    "            # This prevents exploding gradients from destabilizing the training.\n",
    "            clip_value = 1.0 # Do not allow any single gradient to be larger than this.\n",
    "            for p in optimizer_params:\n",
    "                p.grad = np.clip(p.grad, -clip_value, clip_value)\n",
    "\n",
    "            # Update weights\n",
    "            for p in optimizer_params:\n",
    "                p.data -= lr * p.grad\n",
    "                \n",
    "            epoch_loss += batch_loss.data\n",
    "            print(f\"\\rBatch {i//64} | Loss: {batch_loss.data:.4f}\", end=\"\")\n",
    "            \n",
    "        print(f\"\\nEpoch {epoch+1} | Avg Loss: {epoch_loss / (len(X_train)/64):.4f} | Time: {time.time()-start:.1f}s\")\n",
    "        \n",
    "        # Test AUC (still works with probability outputs)\n",
    "        preds = [model.forward(x).data for x in X_test]\n",
    "        try:\n",
    "            print(f\"Test AUC: {roc_auc_score(y_test, preds):.4f}\")\n",
    "        except: pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boson_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
